{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hpXjkPS-6PYI"
      },
      "outputs": [],
      "source": [
        "sentence = \"\"\"Natural Language Processing (NLP) is a crucial part of AI that helps computers understand and work with human language.\n",
        "It's about teaching computers to read, understand, and even generate text like humans do. NLP is used in many applications like chatbots,\n",
        "language translation, and analyzing sentiments in text. In NLP, computers learn to recognize patterns and make sense of words and sentences.\n",
        "They use techniques like breaking down text into smaller parts, figuring out the role of each word, and identifying names or important terms.\n",
        "However, NLP still faces challenges like understanding slang or figuring out the meaning of words depending on the context.\n",
        "Despite these challenges, NLP keeps improving with better technology and methods. It's becoming more useful in areas like healthcare,\n",
        "finance, and customer service. As technology advances, NLP will continue to make it easier for humans to interact with computers and for computers to understand us better.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjOX69Sv67NH",
        "outputId": "6cde7838-ff9f-470a-a905-7a0cc86abf84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize as wt\n",
        "sentence = wt(sentence)"
      ],
      "metadata": {
        "id": "bjgWMAkT6saT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist as fd"
      ],
      "metadata": {
        "id": "zhQLto1u7TCT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fd(sentence).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMbKvna7ZYJ",
        "outputId": "f69da68f-5e3f-4297-9bbd-7b04a0614e50"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 12),\n",
              " ('and', 9),\n",
              " ('.', 9),\n",
              " ('NLP', 6),\n",
              " ('computers', 5),\n",
              " ('to', 5),\n",
              " ('like', 5),\n",
              " ('of', 4),\n",
              " ('understand', 3),\n",
              " ('with', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HERE WE HAVE TO REMOVE ALL THE PUNCTUATIONS AND WE ONLY NEED TO COUNT WORD FREQUENCY**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wVXZ1E1c7i62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation\n",
        "sentence_no_punct = []\n",
        "for i in sentence:\n",
        "    for j in list(string.punctuation):\n",
        "        i = i.replace(j,'').lower()\n",
        "    sentence_no_punct.append(i)"
      ],
      "metadata": {
        "id": "veZImpu77Zpg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **REMOVING THE STOP WORDS**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ywnRSTrZ9foS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddXl2ctZ9d-D",
        "outputId": "b719a30d-45ec-4ce7-b245-2cb1d60cf7e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words = [word for word in sentence_no_punct if word.lower() not in stop_words]\n",
        "\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXJW7Cgx9398",
        "outputId": "b2e017c1-907d-4049-a1d7-7b9b908ea698"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', '', 'nlp', '', 'crucial', 'part', 'ai', 'helps', 'computers', 'understand', 'work', 'human', 'language', '', 'teaching', 'computers', 'read', '', 'understand', '', 'even', 'generate', 'text', 'like', 'humans', '', 'nlp', 'used', 'many', 'applications', 'like', 'chatbots', '', 'language', 'translation', '', 'analyzing', 'sentiments', 'text', '', 'nlp', '', 'computers', 'learn', 'recognize', 'patterns', 'make', 'sense', 'words', 'sentences', '', 'use', 'techniques', 'like', 'breaking', 'text', 'smaller', 'parts', '', 'figuring', 'role', 'word', '', 'identifying', 'names', 'important', 'terms', '', 'however', '', 'nlp', 'still', 'faces', 'challenges', 'like', 'understanding', 'slang', 'figuring', 'meaning', 'words', 'depending', 'context', '', 'despite', 'challenges', '', 'nlp', 'keeps', 'improving', 'better', 'technology', 'methods', '', 'becoming', 'useful', 'areas', 'like', 'healthcare', '', 'finance', '', 'customer', 'service', '', 'technology', 'advances', '', 'nlp', 'continue', 'make', 'easier', 'humans', 'interact', 'computers', 'computers', 'understand', 'us', 'better', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd(filtered_words).most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wEKnXh472ys",
        "outputId": "515340df-7308-4301-9d55-faf34c2c1a80"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 23),\n",
              " ('nlp', 6),\n",
              " ('computers', 5),\n",
              " ('like', 5),\n",
              " ('language', 3),\n",
              " ('understand', 3),\n",
              " ('text', 3),\n",
              " ('humans', 2),\n",
              " ('make', 2),\n",
              " ('words', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}